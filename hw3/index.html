<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Summer 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Jake Pastoria</div>

		<br>

		<br>

		Link to main webpage: <a href="https://cal-cs184.github.io/hw-webpages-su25-Jake-Pastoria/">https://cal-cs184.github.io/hw-webpages-su25-Jake-Pastoria/</a>

		<br>
		
		Link to GitHub repository: <a href="https://github.com/cal-cs184/hw-pathtracer-updated-jp">https://github.com/cal-cs184/hw-pathtracer-updated-jp</a>
		
		<figure>
			<img src="p5_2_1.png" alt="Cornell Boxes with Bunnies" style="width:500px"/>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		This assignment serves as a comprehensive introduction to ray tracing, touching on ray generation & intersection, optimization techniques, direct & indirect illumination with diffuse
		BSDFs for global illumination, and adaptive sampling. It begins with the challenge of casting a ray into the scene from the camera, and tracking where that ray hits. From there, a 
		Bounding Volume Hierarchy is used to vastly improve render times and computational efficiency. After this, adding both direct and indirect illumination types allows for the creation of 
		highly realistic renders with global illumination that emulates how real light bounces. Finally, adaptive sampling is used to reduce sampling on pixels that have already been deemed 
		as 'converged' to a certain color.
		<br><br> 
		
		The most fascinating aspect of this project was the initial cast of the camera rays, which involved taking coordinates from the image space, casting a ray in the camera space, and 
		transforming this ray into the world space. Learning how to take a coordinate on an image plane and translate it into a ray that bounces and lives in the scene gives me a much stronger 
		intuition about computer graphics as a whole. 

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		In Part 1, I implemented ray generation and ray-triangle/ray-circle intersection, which allows the most basic ray tracing. I began this process by generating rays that convert coordinates 
		in the Image Space into a Ray in the camera space. This ray is defined by the ray equation: 
		
		\[r(t) = o + td\]

		Here, \(o\) is the origin of the ray, \(d\) is the direction (a 3-dimensional vector) that the ray points, and \(t\) is the time/distance along the vector \(d\) starting from \(o\).
		In the camera space, we define this "Camera Ray" to originate from \(o = (0,0,0)\), and point towards the "sensor" of the camera which is located at \(z = -1\). Finally, we can 
		rotate this ray into the world space and place it at the camera's position, which places the ray into our scene.

		<br><br>

		To fill in each pixel on the screen, we generate numerous rays per pixel, and simply find the average scene radiance along those rays. For this beginning section, the estimated radiance 
		along any given ray is simply either the direction that the ray points or the normal of the object it hits. All of the work so far results in the following image, which represents 
		the color of a pixel as the direction that the ray points:

		<figure>
			<img src="p1_1.png" alt="Cornell Boxes with Bunnies" style="width:50%"/>
			<figcaption>banana.dae</figcaption>
		</figure>


		The next step is to implement ray-triangle and ray-circle intersections. For circles, the solutions for the intersections can be easily calculated by plugging in the ray equation to the 
		circle equation. Ray-triangle intersection is significantly more difficult, as this involves multiple steps in order to detect collisions. My method first calculates if the ray intersects 
		with the plane that the triangle lays inside of. If there is an intersection with the plane, I find the value of \(t\) where this intersection happens. As long as this t is in between the 
		predefined minimum and maximums, we now need to determine whether this point lies inside of the triangle. To do this, I used the geometric interpretation of the Barycentric coordinate 
		system, which involves finding the proportional areas of \(	α\), \(	β\), and \(γ\). Using these three values, we can tell if the ray intersects inside the triangle by making sure that 
		these three values are all greater than 0 (in addition to some other checks to make sure we don't include points outside the edges of the triangle). 

		<br><br>

		Here are the renders generated using the previously described methods:
		<br><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p1_2.png" width="400px"/>
				  
				</td>
				<td style="text-align: center;">
				  <img src="p1_3.png" width="400px"/>
				  
				</td>
			</table>
		</div>
		<figure>
			<img src="p1_4.png" alt="Cornell Boxes with Bunnies" style="width:400px"/>
		
		</figure>
		
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		We can use a Bounding Volume Hierarchy (BVH) to optimize our ray tracing by grouping together primitives and creating combined bounding boxes. This Hierarchy is a binary tree, with each node 
		pointing to its left and right sub-nodes that either contain more connections or are leaf nodes. This process starts by taking in a list of all the primitives and generating a root node 
		with a bounding box that contains all the primitives. 
		<br><br>
		From there, we need to establish a heuristic for where to split our bounding box and continue creating the sub-nodes. 
		My method finds the axis (\(x\), \(y\), or \(z\)) that contains the largest extent (the largest difference between the min and max), as this essentially means it has the most variance.
		 This method assumes that the dimension with the most variance captures the most information about our mesh (similar to the thought process of Principal Component Analysis) and is 
		therefore the best to split across. After finding the mean of the centroids of all the primitives bounding boxes along this axis, I split at that value.
		<br><br>
		We can use this BVH to vastly decrease the rendering team needed for each dae file. Here are some examples of highly complex .dae files:
		<br><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p2_1.png" width="400px"/>
				  <figcaption>cow.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p2_2.png" width="400px"/>
				  <figcaption>lucy.dae</figcaption>
				</td>
			  </tr>
			  </table>
		</div>
		<figure>
			<img src="p2_3.png" alt="Cornell Boxes with Bunnies" style="width:400px"/>
			<figcaption>maxplanck.dae</figcaption>
		</figure>

		The BVH has reduced the computational load from \(O(n)\) to \(O(log(n))\), which results in drastic differences in rendering times for scenes with moderately and highly complex meshes. 
		We can explore this time reduction for moderately complex meshes, such as cow.dae. Without using a BVH, this image below takes 44.05 seconds to render. After adding the BVH, the rendering 
		time drastically drops to 0.25 seconds: <br> <br>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p2_4.png" width="400px"/>
				  <figcaption>cow.dae w/o BVH (44.05 seconds)</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p2_5.png" width="400px"/>
				  <figcaption>cow.dae w/ BVH (0.25 seconds)</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<br> <br>
		This speed increase is similar for all moderately complex scenes, such as beetle.dae. We can see that rendering without the BVH takes 58.9 seconds, while rendering with takes about 0.3 
		seconds. 
		<br> <br>


		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p2_6.png" width="400px"/>
				  <figcaption>beetle.dae w/o BVH (58.9 seconds)</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p2_7.png" width="400px"/>
				  <figcaption>beetle.dae w/ BVH (0.3 seconds)</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<br> <br>
		Due to the BVH, each ray no longer needs to check every primitive during rendering, significantly reducing the computational load of ray tracing. The bounding boxes 
		define the potential region in which any enclosed primitive could be hit, allowing us to quickly eliminate primitives that the ray couldn't possibly intersect.


		<h2>Part 3: Direct Illumination</h2>
		Through the use of direct illumination, we can implement our first lighting system. In this part, we give each primitive a material using a Bidirectional Scattering Distribution
		Function (BSDF), mainly using diffuse BSDFs that send light out equally in all directions. After giving these primitives a material, we can now cast rays into the scene. <br><br>
		When these rays hit a point on a primitive, we need to determine how much light that point adds to our ray, which involves considering all the light that could be hitting this 
		specific point from other parts of the scene. From a conceptual approach, this means that we need to send out rays from this point and test if they hit a light. If a ray hits a light, 
		then we know that this point is lit, adding to the radiance of our ray. Computationally, we need to approximate this, which leads us to two different sampling methods: Uniform Hemisphere 
		Sampling, and Importance Sampling of the lights. 
		
		<br><br>
		Uniform Hemisphere Sampling involves sampling uniformly at random in a hemisphere around the point that is struck by the original ray. In essence, sending out rays at random 
		gives us an estimation of how light from the scene arrives at this point. While this is an intuitive way to estimate the amount of light hitting any given point, the inconsistency and 
		randomness associated with this method often create a noisy result as seen below: <br><br>
		

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p3_hemisphere.png" width="400px"/>
				  <figcaption>Uniform Hemisphere Sampling CBbunny.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p3_hemisphere2.png" width="400px"/>
				  <figcaption>Uniform Hemisphere Sampling CBspheres_lambertian.dae</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<br><br>

		It's important to notice that this noise is a direct result of the random rays we cast in our samples missing the lights, which lowers the average radiance that is passed back through our 
		ray. The next sampling method serves as a method of reducing this noise, as instead of casting rays out randomly, we only cast rays towards lights.

		<br><br>

		This next method is a type of importance sampling, and in this case, we are choosing to only sample the lights directly. When our ray hits a point on a primitive, we no longer send 
		out rays in random directions; we instead send them directly towards the lights. In my implementation, this is done by looping through each light object in the scene and sending
	    rays randomly to different parts of the light (point lights are only sampled once). Similar to the previous section, if these rays don't intersect another object before this light then we add 
		to our rays radiance. This method generally results in less noisy renders: <br><br>
		

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p3_importance.png" width="400px"/>
				  <figcaption>Importance Sampling Lights CBbunny.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p3_importance2.png" width="400px"/>
				  <figcaption>Importance Sampling Lights CBspheres_lambertian.dae</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<br><br>

		The images above show the drastic reduction in noise as a result of importance sampling the lights rather than sampling uniformly at random for reasons listed above. In addition, 
		sending rays only at the lights lowers excess computational work, as this reduces the number of rays that end up missing a light source. Visually, importance sampling results in 
		significantly better renders as a result of its consistent shading and decrease in noise. 
		
		<br><br>

		It is important to note that the results seen in the images above are highly dependent on the parameters we set for our system. Some important parameters are the number of camera rays per pixel,
		max ray depth, and the number of samples per area light. We can see that the amount of noise, even in light sampling, varies when we change the number of rays to sample each 
		area light with. The results below show 1, 4, 16, and 64 samples per area light with 1 sample per pixel:
		<br><br>

				<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p3_1.png" width="400px"/>
				  <figcaption>1 Sample per light</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p3_4.png" width="400px"/>
				  <figcaption>4 Samples per light</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p3_16.png" width="400px"/>
				  <figcaption>16 Samples per light</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p3_64.png" width="400px"/>
				  <figcaption>64 Samples per light</figcaption>
				</td>
			  </tr>
			  </table>
		</div>
		<br><br>

		As demonstrated in the pictures above, a lower sampling rate per area light, even in importance sampling results, also results noisy soft shadows and colors. This noise is caused by points that are next to each 
		other sampling different parts of the light, which may cause the ray to be blocked by an object despite the points being nearly identical. As we increase the number of samples per area
		light, this effect diminishes. 


		<h2>Part 4: Global Illumination</h2>
		While the direct illumination shown above provides a baseline level of lighting for objects in the scene, achieving visual richness requires incorporating global illumination, 
		which accounts for indirect lighting. Global illumination creates a more realistic and immersive image by simulating how light bounces off multiple surfaces before reaching the camera.
		<br><br>To implement this, I wrote a recursive function that accumulates radiance from both direct and indirect bounces. When a camera ray first hits a surface at point
		\(p\), we add the direct radiance calculated in the previous part. This initial ray starts at depth = 0, and as long as we haven't hit our maximum depth, a new ray is created at
		\(p\) pointing in a random hemispherical direction. This ray recursively calls the same function, contributing its own radiance (direct and any further indirect bounces) back to the 
		original ray. 
		<br><br>
		The result of this global illumination, which adds both direct and indirect lighting, are shown below:

		<br><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4_2_1.png" width="400px"/>
				  <figcaption>CBbunny.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_2_2.png" width="400px"/>
				  <figcaption>CBspheres_lambertian.dae</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<br><br>

		One way to better understand the role of indirect illumination is to isolate it from direct lighting. In the render below, only direct illumination contributes to the radiance of 
		each pixel, meaning only rays that bounce off a primitive and go right into a light. 
		
		<figure>
			<img src="p4_3_1.png" alt="Cornell Boxes with Bunnies" style="width:400px"/>
			<figcaption>Direct Illumination Only</figcaption>
		</figure>
		
		We can see that when we isolate the direct illumination, it looks identical to the previous part. The main characteristic of this illumination type is the harsh shadows and the 
		lack of influence that objects have on each other in the scene (such as how the red and blue walls do not reflect any light onto the spheres).

		<br><br>

		Let's now isolate the indirect illumination:

		<figure>
			<img src="p4_3_2.png" alt="Cornell Boxes with Bunnies" style="width:400px"/>
			<figcaption>Indirect Illumination Only</figcaption>
		</figure>

		<br><br>

		The indirect illumination alone effectively adds ambient lighting to the objects in the scene, since light is now able to reach objects that were previously in darker regions. Compared 
		to the direct lighting, this render is more uniformly lit as a result of the indirect light bouncing.

		<br><br>

		Now, let's visualize only the light from the very last ray sent out by setting 'isAccumBounces = false' and adjusting the maximum number of bounces per ray:  

		<br><br>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4_4_f_0.png" width="225px"/>
				  <figcaption>0 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_f_1.png" width="225px"/>
				  <figcaption>1 Bounce</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_f_2.png" width="225px"/>
				  <figcaption>2 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_f_3.png" width="225px"/>
				  <figcaption>3 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_f_4.png" width="225px"/>
				  <figcaption>4 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_f_5.png" width="225px"/>
				  <figcaption>5 Bounces</figcaption>
				</td>
				</tr>
				</table>
		</div>
		<br><br>

		Extracting the light contribution from the final bounce helps illustrate how indirect illumination enhances the visual richness of a render. In the images with a 
		max depth of 2 or 3 bounces, areas that remained dark with only 1 bounce become noticeably brighter. This is because the additional bounces (that on the 1st bounce would have gone 
		into the floor rather than a light source) are now
		bouncing back into the light. These additional bounces simulate how real light would reflect throughout the scene, as we add the radiance from these extra bounces together to create 
		softer shadows and smoother illumination. Rasterization can't replicate global illumination in this way, as it's unable to trace light paths 
		 throughout the scene or add ambient lighting that adapts to the scene geometry.

		<br><br>

		With this in mind, we can examine each render using the same number of bounces, this time accumulating both the direct and indirect light: 
		
		<br><br>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4_4_t_0.png" width="225px"/>
				  <figcaption>0 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_t_1.png" width="225px"/>
				  <figcaption>1 Bounce</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_t_2.png" width="225px"/>
				  <figcaption>2 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_t_3.png" width="225px"/>
				  <figcaption>3 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_t_4.png" width="225px"/>
				  <figcaption>4 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_4_t_5.png" width="225px"/>
				  <figcaption>5 Bounces</figcaption>
				</td>
				</tr>
				</table>
		</div>

		<br><br>

		The accumulated bounces in these renders combine the light from each individual bounce from the previous set of images. The combination of all these individual bounces simulates the 
		effect of ambient lighting. 

		<br><br>

		While global illumination creates a realistic look, it can also take a long time to render. One way to reduce the computational load and optimize our estimation of light in our samples 
		is to use "Russian Roulette" rendering. In this method, we're able to set both a max depth as well as a probability of termination, which can prematurely end our indirect lighting 
		recursion. The results of this technique can be seen below:

		<br><br>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4_5_0.png" width="225px"/>
				  <figcaption>0 Bounces (Russian Roulette)</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_5_1.png" width="225px"/>
				  <figcaption>1 Bounce</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_5_2.png" width="225px"/>
				  <figcaption>2 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_5_3.png" width="225px"/>
				  <figcaption>3 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_5_4.png" width="225px"/>
				  <figcaption>4 Bounces</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_5_100.png" width="225px"/>
				  <figcaption>100 Bounces</figcaption>
				</td>
				</tr>
				</table>
		</div>

		<br><br>

		One important parameter for global illumination is the number of samples that we take per pixel, as the reduces the noise associated with sending rays out in random directions to 
		approximate the indirect light. As we change this parameter, the renders become less noisy:
		
		<br><br>
		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4_6_1.png" width="225px"/>
				  <figcaption>1 Sample</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_6_2.png" width="225px"/>
				  <figcaption>2 Samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_6_4.png" width="225px"/>
				  <figcaption>4 Samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_6_8.png" width="225px"/>
				  <figcaption>8 Samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_6_16.png" width="225px"/>
				  <figcaption>16 Samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_6_64.png" width="225px"/>
				  <figcaption>64 Samples</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4_6_1024.png" width="225px"/>
				  <figcaption>1024 Samples</figcaption>
				</td>
				</tr>
				</table>
		</div>

		<h2>Part 5: Adaptive Sampling</h2>
		The previous set of renders demonstrated how the main method for reducing the noise associated with Monte Carlo path tracing and global illumination is to increase the number of 
		samples per pixel. Increasing this parameter greatly increases the computational load, and wastes samples on pixels that have already converged to a certain color. To account for this,
		we can use adaptive sampling to only increase the number of samples per pixel for pixels that don't converge quickly.

		<br><br>

		To implement this, we keep track of the mean μ and standard deviation σ of the samples we've traced for a given pixel. According to the assignment specification, we establish a variable
		\(I\) that represents the convergence of a given pixel:

		\[I = 1.96 \cdot \frac{\sigma}{\sqrt{n}}\]


		We can use this formula (which is derived from a 95% confidence interval) to track a pixel's convergence, as increasing variance results in an increase in \(I\). If 
		\(I \le maxTolerance \cdot \mu \), then we say that the pixel has converged and doesn't need to be sampled anymore. 

		<br><br>

		We can map where the sample \(n\) where we've deemed that the pixel has 'converged' by dividing it by the maximum number of samples. This gives us a 'rate' map for each render, which 
		can be seen in the examples below:
		
		<br><br>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p5_1_2.png" width="400px"/>
				  <figcaption>CBbunny.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p5_1_1.png" width="400px"/>
				  <figcaption>CBbunny.dae Rate map</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p5_2_1.png" width="400px"/>
				  <figcaption>CBspheres_lambertian.dae</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p5_2_2.png" width="400px"/>
				  <figcaption>CBspheres_lambertian.dae Rate map</figcaption>
				</td>
			  </tr>
			  </table>
		</div>

		<h3>AI Acknowledgement</h3>
		In this assignment, the use of ChatGPT was minimal and was restricted to conceptual questions about ray-tracing or minor debugging. In order to have a good grasp of the concepts 
		before implementing them, I'd initially go through the lecture slides for review. When I wasn't sure about a concept, I would prompt ChatGPT to
		explain it in more detail and provide context for the concept itself. Using LLMs in this way makes the learning process more digestible and less frustrating, as I'm able to gain a 
		much stronger conceptual understanding of the content. It was this strong conceptual understanding that made it easier for me to finish the project by myself.     
		
		<!-- <h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. -->
		
		
		</div>
	</body>
</html>